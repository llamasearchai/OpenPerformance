[build-system]
requires = ["setuptools>=69.0.0", "wheel>=0.42.0"]
build-backend = "setuptools.build_meta"

[project]
name = "openperformance"
version = "1.0.3"
description = "Enterprise-grade ML Performance Engineering Platform for optimization, monitoring, and deployment"
readme = "README.md"
license = {text = "MIT"}
authors = [
    {name = "OpenPerformance Team", email = "team@openperformance.ai"},
]
maintainers = [
    {name = "OpenPerformance Maintainers", email = "maintainers@openperformance.ai"},
]
keywords = ["ml", "performance", "optimization", "monitoring", "deployment", "mlops", "ai"]
classifiers = [
    "Development Status :: 5 - Production/Stable",
    "Intended Audience :: Developers",
    "Intended Audience :: Science/Research",
    "License :: OSI Approved :: MIT License",
    "Operating System :: OS Independent",
    "Programming Language :: Python :: 3",
    "Programming Language :: Python :: 3.10",
    "Programming Language :: Python :: 3.11",
    "Programming Language :: Python :: 3.12",
    "Topic :: Scientific/Engineering :: Artificial Intelligence",
    "Topic :: Software Development :: Libraries :: Python Modules",
]
requires-python = ">=3.10"
dependencies = [
    "fastapi>=0.104.0,<0.110.0",
    "uvicorn[standard]>=0.24.0,<0.30.0",
    "pydantic>=2.5.0,<3.0.0",
    "pydantic-settings>=2.1.0",
    "typer[all]>=0.9.0,<0.15.0",
    "numpy>=1.24.0,<2.0.0",
    "sqlalchemy>=2.0.0,<3.0.0",
    "redis>=5.0.0,<6.0.0",
    "psutil>=5.9.0",
    "openai>=1.20.0",
    "httpx>=0.25.0,<0.30.0",
    "python-jose[cryptography]>=3.3.0",
    "passlib[bcrypt]>=1.7.4",
    "python-multipart>=0.0.6",
]

[project.optional-dependencies]
dev = [
    "pytest>=7.4.0",
    "pytest-asyncio>=0.21.0",
    "pytest-cov>=4.1.0",
    "pytest-mock>=3.12.0",
    "black>=23.11.0",
    "ruff>=0.1.0",
    "mypy>=1.7.0",
    "bandit[toml]>=1.7.5",
    "pip-audit>=2.7.0",
    "pre-commit>=3.6.0",
    "tox>=4.0.0",
]
docs = [
    "mkdocs>=1.5.0",
    "mkdocs-material>=9.4.0",
    "sphinx>=7.2.0",
]
gpu = [
    "nvidia-ml-py>=12.535.0",
    "pynvml>=11.5.0",
    "GPUtil>=1.4.0",
]
ml = [
    "torch>=2.1.0",
    "torchvision>=0.16.0",
    "torchaudio>=2.1.0",
    "tensorflow>=2.13.0",
    "transformers>=4.36.0",
    "accelerate>=0.25.0",
    "datasets>=2.16.0",
    "jax[cpu]>=0.4.0",
    "jaxlib>=0.4.0",
    "flax>=0.7.0",
    "optax>=0.1.7",
    "scikit-learn>=1.3.0",
    "xgboost>=2.0.0",
    "lightgbm>=4.1.0",
    "catboost>=1.2.0",
]
dist = [
    "ray[default]>=2.8.0",
    "dask[complete]>=2023.12.0",
    "distributed>=2023.12.0",
    "deepspeed>=0.12.0",
    "fairscale>=0.4.13",
]
observability = [
    "prometheus-client>=0.19.0",
    "opentelemetry-api>=1.21.0",
    "opentelemetry-sdk>=1.21.0",
    "opentelemetry-instrumentation-fastapi>=0.42b0",
    "rich>=13.6.0",
    "structlog>=23.2.0",
]
security = [
    "slowapi>=0.1.9",
    "argon2-cffi>=23.1.0",
    "pyotp>=2.9.0",
    "python-decouple>=3.8",
]
profiling = [
    "py-spy>=0.3.14",
    "memory-profiler>=0.61.0",
    "line-profiler>=4.1.0",
]
visualization = [
    "plotly>=5.17.0",
    "matplotlib>=3.8.0",
    "seaborn>=0.13.0",
    "bokeh>=3.3.0",
]
cloud = [
    "boto3>=1.34.0",
    "google-cloud-storage>=2.10.0",
    "azure-storage-blob>=12.19.0",
]
io = [
    "aiofiles>=23.2.0",
    "pyarrow>=14.0.0",
    "h5py>=3.10.0",
    "zarr>=2.16.0",
    "fsspec>=2023.12.0",
]
serde = [
    "msgpack>=1.0.7",
    "orjson>=3.9.10",
    "ujson>=5.8.0",
    "avro>=1.11.3",
]
docs-site = [
    "mkdocs>=1.5.0",
    "mkdocs-material>=9.4.0",
]

[project.urls]
Homepage = "https://github.com/openperformance/openperformance"
Documentation = "https://openperformance.io"
Repository = "https://github.com/openperformance/openperformance.git"
"Bug Tracker" = "https://github.com/openperformance/openperformance/issues"
Changelog = "https://github.com/openperformance/openperformance/blob/main/CHANGELOG.md"

[project.scripts]
openperf = "mlperf.cli.main:app"
mlperf = "mlperf.cli.main:app"
openperf-server = "mlperf.api.main:start_server"
openperf-worker = "mlperf.workers.main:celery_app.start"

[tool.setuptools]
include-package-data = true

[tool.setuptools.packages.find]
where = ["python"]
include = ["mlperf*"]

[tool.setuptools.package-data]
"mlperf" = ["*.json", "*.yaml", "*.yml", "*.toml"]

[tool.black]
line-length = 100
target-version = ["py310", "py311", "py312"]
include = '\.pyi?$'
extend-exclude = '''
/(
    \.eggs
  | \.git
  | \.hg
  | \.mypy_cache
  | \.tox
  | \.venv
  | _build
  | buck-out
  | build
  | dist
  | node_modules
  | venv
  | \.pytest_cache
  | \.ruff_cache
)/
'''

[tool.ruff]
line-length = 100
target-version = "py310"
select = [
    "E",    # pycodestyle errors
    "W",    # pycodestyle warnings
    "F",    # pyflakes
    "I",    # isort
    "C",    # flake8-comprehensions
    "B",    # flake8-bugbear
    "UP",   # pyupgrade
    "S",    # flake8-bandit
    "A",    # flake8-builtins
    "DTZ",  # flake8-datetimez
    "ICN",  # flake8-import-conventions
    "PIE",  # flake8-pie
    "PT",   # flake8-pytest-style
    "RET",  # flake8-return
    "SIM",  # flake8-simplify
    "ARG",  # flake8-unused-arguments
    "PD",   # pandas-vet
    "PGH",  # pygrep-hooks
    "PL",   # pylint
    "NPY",  # numpy-specific rules
    "RUF",  # ruff-specific rules
]
ignore = [
    "E501",  # line too long (handled by black)
    "B008",  # do not perform function calls in argument defaults
    "C901",  # too complex
    "S101",  # use of assert detected
    "S104",  # possible binding to all interfaces
    "S105",  # possible hardcoded password
    "S106",  # possible hardcoded password
    "S107",  # possible hardcoded password
]
exclude = [
    ".bzr",
    ".direnv",
    ".eggs",
    ".git",
    ".hg",
    ".mypy_cache",
    ".nox",
    ".pants.d",
    ".ruff_cache",
    ".svn",
    ".tox",
    ".venv",
    "__pypackages__",
    "_build",
    "buck-out",
    "build",
    "dist",
    "node_modules",
    "venv",
]

[tool.ruff.per-file-ignores]
"tests/*" = ["S101", "ARG", "PLR2004"]
"scripts/*" = ["S101", "T201"]
"python/mlperf/cli/*" = ["T201"]

[tool.isort]
profile = "black"
line_length = 100
multi_line_output = 3
include_trailing_comma = true
force_grid_wrap = 0
use_parentheses = true
ensure_newline_before_comments = true
split_on_trailing_comma = true
skip_glob = ["*/migrations/*", "*/venv/*", "*/node_modules/*"]

[tool.mypy]
python_version = "3.10"
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true
strict_equality = true
show_error_codes = true
show_column_numbers = true
pretty = true
plugins = ["pydantic.mypy", "sqlalchemy.ext.mypy.plugin"]

[[tool.mypy.overrides]]
module = [
    "torch.*",
    "tensorflow.*",
    "jax.*",
    "horovod.*",
    "deepspeed.*",
    "mpi4py.*",
    "nvidia_ml_py.*",
    "pynvml.*",
    "transformers.*",
    "accelerate.*",
    "datasets.*",
    "ray.*",
    "dask.*",
]
ignore_missing_imports = true

[tool.pytest.ini_options]
testpaths = ["tests", "python/tests"]
python_files = "test_*.py"
python_classes = "Test*"
python_functions = "test_*"
addopts = [
    "--cov=mlperf",
    "--cov-report=xml",
    "--cov-report=term-missing",
    "--cov-report=html",
    "--cov-branch",
    "--cov-fail-under=13",
    "--strict-markers",
    "--tb=short",
    "--maxfail=1",
    "-ra",
    "--ignore=node_modules",
    "--ignore=venv",
    "--ignore=.venv",
]
markers = [
    "slow: marks tests as slow (deselect with '-m \"not slow\"')",
    "integration: marks tests as integration tests",
    "gpu: marks tests that require GPU",
    "distributed: marks tests that require distributed setup",
    "benchmark: marks performance benchmark tests",
    "unit: marks unit tests",
    "e2e: marks end-to-end tests",
]
asyncio_mode = "auto"
filterwarnings = [
    "ignore::DeprecationWarning",
    "ignore::PendingDeprecationWarning",
]

[tool.coverage.run]
source = ["mlperf"]
branch = true
parallel = true
omit = [
    "*/tests/*",
    "*/test_*",
    "*/__pycache__/*",
    "*/venv/*",
    "*/virtualenv/*",
    "*/.venv/*",
    "*/migrations/*",
    "*/conftest.py",
    "*/setup.py",
]

[tool.coverage.report]
precision = 2
show_missing = true
skip_covered = false
exclude_lines = [
    "pragma: no cover",
    "def __repr__",
    "if self.debug:",
    "if settings.DEBUG",
    "raise AssertionError",
    "raise NotImplementedError",
    "if 0:",
    "if __name__ == .__main__.:",
    "class .*\\bProtocol\\):",
    "@(abc\\.)?abstractmethod",
    "except ImportError:",
    "if TYPE_CHECKING:",
]

[tool.coverage.html]
directory = "htmlcov"

[tool.coverage.xml]
output = "coverage.xml"

[tool.bandit]
targets = ["python/mlperf"]
exclude_dirs = ["tests", "venv", ".venv", "node_modules"]
severity = "medium"
confidence = "medium"
skips = ["B101", "B601"]

[tool.pylint.messages_control]
disable = [
    "C0111",  # missing-docstring
    "C0103",  # invalid-name
    "R0903",  # too-few-public-methods
    "R0913",  # too-many-arguments
    "W0622",  # redefined-builtin
    "W0613",  # unused-argument
]

[tool.pylint.format]
max-line-length = 100

[tool.pydantic-mypy]
init_forbid_extra = true
init_typed = true
warn_required_dynamic_aliases = true
warn_untyped_fields = true